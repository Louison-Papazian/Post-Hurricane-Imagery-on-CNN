{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\Utilisateur\\Documents\\GitHub\\Post-Hurricane-Imagery-on-CNN'\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(),transforms.Resize((150,150)), transforms.Pad(1)])\n",
    "\n",
    "\n",
    "#Train\n",
    "train = datasets.ImageFolder(data_dir + \"/train_another\",transform = trans)\n",
    "\n",
    "#Validation\n",
    "validation = datasets.ImageFolder(data_dir + \"/validation_another\",transform = trans)\n",
    "\n",
    "#train loader\n",
    "train_loader = torch.utils.data.DataLoader(train, 20, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "\n",
    "#test loader\n",
    "val_loader = torch.utils.data.DataLoader(validation, 20, shuffle = False, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction permettant d'obtenir l'accuracy des modèles\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'une classe de suivis des modèles avec prediction sur les données de validation\n",
    "#et metrics d'analyse\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model de l'article en pytorch avec comme base la classe de suivi des modèles\n",
    "class NewCNN(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3,64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(64,128, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(128,128, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128*15*15, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "model = NewCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation du modèle pour l'entrainement\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    step = 0\n",
    "    for batch in val_loader:\n",
    "        outputs.append(model.validation_step(batch))\n",
    "        step += 1\n",
    "        if step == 50:\n",
    "            break\n",
    "        \n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        step = 0\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            step += 1\n",
    "            if step == 100:\n",
    "                break \n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewCNN(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): Linear(in_features=41472, out_features=512, bias=True)\n",
       "    (12): ReLU()\n",
       "    (13): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (14): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.7391, val_loss: 0.7831, val_acc: 0.0010\n",
      "Epoch [1], train_loss: 0.6069, val_loss: 0.6132, val_acc: 0.6730\n",
      "Epoch [2], train_loss: 0.5121, val_loss: 0.5446, val_acc: 0.7580\n",
      "Epoch [3], train_loss: 0.4879, val_loss: 0.7452, val_acc: 0.5410\n",
      "Epoch [4], train_loss: 0.4650, val_loss: 0.3768, val_acc: 0.9390\n",
      "Epoch [5], train_loss: 0.4481, val_loss: 0.3676, val_acc: 0.9480\n",
      "Epoch [6], train_loss: 0.4323, val_loss: 0.4112, val_acc: 0.8990\n",
      "Epoch [7], train_loss: 0.4231, val_loss: 0.3499, val_acc: 0.9670\n",
      "Epoch [8], train_loss: 0.4133, val_loss: 0.4134, val_acc: 0.8980\n",
      "Epoch [9], train_loss: 0.4040, val_loss: 0.3620, val_acc: 0.9500\n",
      "Epoch [10], train_loss: 0.4011, val_loss: 0.4090, val_acc: 0.9070\n",
      "Epoch [11], train_loss: 0.3977, val_loss: 0.5155, val_acc: 0.7900\n",
      "Epoch [12], train_loss: 0.3991, val_loss: 0.3425, val_acc: 0.9720\n",
      "Epoch [13], train_loss: 0.3932, val_loss: 0.3488, val_acc: 0.9660\n",
      "Epoch [14], train_loss: 0.3870, val_loss: 0.3807, val_acc: 0.9320\n",
      "Epoch [15], train_loss: 0.3824, val_loss: 0.3281, val_acc: 0.9850\n",
      "Epoch [16], train_loss: 0.3811, val_loss: 0.3644, val_acc: 0.9540\n",
      "Epoch [17], train_loss: 0.3844, val_loss: 0.3941, val_acc: 0.9160\n",
      "Epoch [18], train_loss: 0.3771, val_loss: 0.3616, val_acc: 0.9490\n",
      "Epoch [19], train_loss: 0.3704, val_loss: 0.3533, val_acc: 0.9600\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "opt_func = torch.optim.RMSprop\n",
    "lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.3629, val_loss: 0.3364, val_acc: 0.9800\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66168a667a11ac16aca0d0d9742c8419f93457ff66115bf85239ea370d417636"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
