{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0eeeefa",
   "metadata": {},
   "source": [
    "# Création de CNN à partir des recherches de CAO et CHOE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b1e3c",
   "metadata": {},
   "source": [
    "## Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76789c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm==3.3.5 in c:\\users\\sibghi\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 1)) (3.3.5)\n",
      "Requirement already satisfied: numpy==1.21.5 in c:\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.21.5)\n",
      "Requirement already satisfied: scikit_learn==1.2.1 in c:\\users\\sibghi\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 3)) (1.2.1)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\sibghi\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: torchinfo==1.7.2 in c:\\users\\sibghi\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 5)) (1.7.2)\n",
      "Requirement already satisfied: torchsummary==1.5.1 in c:\\users\\sibghi\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 6)) (1.5.1)\n",
      "Requirement already satisfied: torchvision==0.14.1 in c:\\users\\sibghi\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 7)) (0.14.1)\n",
      "Requirement already satisfied: xgboost==1.7.3 in c:\\users\\sibghi\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 8)) (1.7.3)\n",
      "Requirement already satisfied: wheel in c:\\anaconda3\\lib\\site-packages (from lightgbm==3.3.5->-r requirements.txt (line 1)) (0.37.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from lightgbm==3.3.5->-r requirements.txt (line 1)) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit_learn==1.2.1->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sibghi\\appdata\\roaming\\python\\python39\\site-packages (from scikit_learn==1.2.1->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda3\\lib\\site-packages (from torch==1.13.1->-r requirements.txt (line 4)) (4.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda3\\lib\\site-packages (from torchvision==0.14.1->-r requirements.txt (line 7)) (9.0.1)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from torchvision==0.14.1->-r requirements.txt (line 7)) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 7)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda3\\lib\\site-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 7)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 7)) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 7)) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796bb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary \n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a1c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des fichiers pour utiliser les fonctions\n",
    "from Medium_CNN import MediumCNN, MediumFit,ConvNet,NewCNN\n",
    "from DC_CNN import CNNet, fit_CNN, val_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ba875",
   "metadata": {},
   "source": [
    "## Importation des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a0f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = datasets.ImageFolder(\"./train_another\",transform = transforms.Compose([\n",
    "    transforms.Resize((150,150)),transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "#Validation\n",
    "validation = datasets.ImageFolder(\"./validation_another\",transform = transforms.Compose([\n",
    "    transforms.Resize((150,150)),transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f3eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement en DataLoader avec batch 128 pour éviter les crashs en entrainement et shuffle\n",
    "#pour mélanger les batchs à chaque étape de l'entrainement\n",
    "train_dl = torch.utils.data.DataLoader(train, 20, shuffle = True, num_workers = 0, pin_memory = True)\n",
    "\n",
    "val_dl = torch.utils.data.DataLoader(validation, 20, shuffle = True,num_workers = 0, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e44f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_damage_dir = './train_another/damage'\n",
    "validation_damage_dir = './validation_another/damage'\n",
    "test_damage_dir = './test_another/damage'\n",
    "\n",
    "train_nodamage_dir = './train_another/no_damage'\n",
    "validation_nodamage_dir = './validation_another/no_damage'\n",
    "test_nodamage_dir = './test_another/no_damage'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0398e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training damage images:  5000\n",
      "total validation damage images:  1000\n",
      "total test damage images:  8000\n",
      "total training no damage images:  5000\n",
      "total validation no damage images:  1000\n",
      "total test no damage images:  1000\n"
     ]
    }
   ],
   "source": [
    "print('total training damage images: ',len(os.listdir(train_damage_dir)))\n",
    "print('total validation damage images: ',len(os.listdir(validation_damage_dir)))\n",
    "print('total test damage images: ',len(os.listdir(test_damage_dir)))\n",
    "\n",
    "print('total training no damage images: ',len(os.listdir(train_nodamage_dir)))\n",
    "print('total validation no damage images: ',len(os.listdir(validation_nodamage_dir)))\n",
    "print('total test no damage images: ',len(os.listdir(test_nodamage_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ec346",
   "metadata": {},
   "source": [
    "## Reproduction du 1er modèle et du meilleure modèle obtenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74405c66",
   "metadata": {},
   "source": [
    "### Reproduction du premier modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09615d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MediumCNN(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "    (13): Linear(in_features=6272, out_features=512, bias=True)\n",
       "    (14): ReLU()\n",
       "    (15): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (16): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definision du premier CNN\n",
    "model = MediumCNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20033898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_epochs = 50\n",
    "#opt_func = torch.optim.RMSprop\n",
    "#lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "#history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd22524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reproduire le 1er modele \n",
    "#data augmentation + RMSprop optimizer \n",
    "num_epochs = 50\n",
    "opt_func = torch.optim.RMSprop\n",
    "lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = MediumFit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596bf312",
   "metadata": {},
   "source": [
    "### Reproduction du meilleur modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b848a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "    (13): Dropout(p=0.5, inplace=False)\n",
       "    (14): Linear(in_features=6272, out_features=512, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (17): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creation du modele en rajoutant dropout \n",
    "#reproduction du 2eme model\n",
    "model2 = ConvNet()\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c8f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.6795, val_loss: 0.6194, val_acc: 0.7420\n",
      "Epoch [1], train_loss: 0.5881, val_loss: 0.5261, val_acc: 0.7940\n",
      "Epoch [2], train_loss: 0.5428, val_loss: 0.5441, val_acc: 0.7520\n",
      "Epoch [3], train_loss: 0.5307, val_loss: 0.5135, val_acc: 0.8010\n",
      "Epoch [4], train_loss: 0.5078, val_loss: 0.4916, val_acc: 0.8120\n",
      "Epoch [5], train_loss: 0.4985, val_loss: 0.4643, val_acc: 0.8470\n",
      "Epoch [6], train_loss: 0.4549, val_loss: 0.4546, val_acc: 0.8570\n",
      "Epoch [7], train_loss: 0.4654, val_loss: 0.4065, val_acc: 0.9070\n",
      "Epoch [8], train_loss: 0.4244, val_loss: 0.4425, val_acc: 0.8690\n",
      "Epoch [9], train_loss: 0.4300, val_loss: 0.4072, val_acc: 0.9100\n",
      "Epoch [10], train_loss: 0.4220, val_loss: 0.4077, val_acc: 0.9120\n",
      "Epoch [11], train_loss: 0.4097, val_loss: 0.4220, val_acc: 0.8870\n",
      "Epoch [12], train_loss: 0.4142, val_loss: 0.4049, val_acc: 0.9060\n",
      "Epoch [13], train_loss: 0.4108, val_loss: 0.4261, val_acc: 0.8840\n",
      "Epoch [14], train_loss: 0.4106, val_loss: 0.3969, val_acc: 0.9220\n",
      "Epoch [15], train_loss: 0.4079, val_loss: 0.3944, val_acc: 0.9170\n",
      "Epoch [16], train_loss: 0.4078, val_loss: 0.4154, val_acc: 0.8890\n",
      "Epoch [17], train_loss: 0.4093, val_loss: 0.3940, val_acc: 0.9140\n",
      "Epoch [18], train_loss: 0.4001, val_loss: 0.3887, val_acc: 0.9160\n",
      "Epoch [19], train_loss: 0.3960, val_loss: 0.3934, val_acc: 0.9140\n",
      "Epoch [20], train_loss: 0.3987, val_loss: 0.4125, val_acc: 0.8980\n",
      "Epoch [21], train_loss: 0.3918, val_loss: 0.4044, val_acc: 0.9110\n",
      "Epoch [22], train_loss: 0.4018, val_loss: 0.4095, val_acc: 0.9050\n",
      "Epoch [23], train_loss: 0.3973, val_loss: 0.3894, val_acc: 0.9190\n",
      "Epoch [24], train_loss: 0.3863, val_loss: 0.4019, val_acc: 0.9080\n",
      "Epoch [25], train_loss: 0.3883, val_loss: 0.4079, val_acc: 0.8990\n",
      "Epoch [26], train_loss: 0.3898, val_loss: 0.3898, val_acc: 0.9190\n",
      "Epoch [27], train_loss: 0.3951, val_loss: 0.3873, val_acc: 0.9240\n",
      "Epoch [28], train_loss: 0.4035, val_loss: 0.3869, val_acc: 0.9240\n",
      "Epoch [29], train_loss: 0.3880, val_loss: 0.3917, val_acc: 0.9190\n",
      "Epoch [30], train_loss: 0.3973, val_loss: 0.3735, val_acc: 0.9380\n",
      "Epoch [31], train_loss: 0.3905, val_loss: 0.3819, val_acc: 0.9310\n",
      "Epoch [32], train_loss: 0.3887, val_loss: 0.3836, val_acc: 0.9270\n",
      "Epoch [33], train_loss: 0.3898, val_loss: 0.4253, val_acc: 0.8800\n",
      "Epoch [34], train_loss: 0.3870, val_loss: 0.3811, val_acc: 0.9270\n",
      "Epoch [35], train_loss: 0.3849, val_loss: 0.3809, val_acc: 0.9310\n",
      "Epoch [36], train_loss: 0.3845, val_loss: 0.3812, val_acc: 0.9320\n",
      "Epoch [37], train_loss: 0.3935, val_loss: 0.3842, val_acc: 0.9290\n",
      "Epoch [38], train_loss: 0.3899, val_loss: 0.4001, val_acc: 0.9060\n",
      "Epoch [39], train_loss: 0.3799, val_loss: 0.3947, val_acc: 0.9120\n",
      "Epoch [40], train_loss: 0.3800, val_loss: 0.3707, val_acc: 0.9390\n",
      "Epoch [41], train_loss: 0.3693, val_loss: 0.3947, val_acc: 0.9170\n",
      "Epoch [42], train_loss: 0.3828, val_loss: 0.4279, val_acc: 0.8880\n",
      "Epoch [43], train_loss: 0.3906, val_loss: 0.3748, val_acc: 0.9410\n",
      "Epoch [44], train_loss: 0.3789, val_loss: 0.3710, val_acc: 0.9390\n",
      "Epoch [45], train_loss: 0.3812, val_loss: 0.3664, val_acc: 0.9470\n",
      "Epoch [46], train_loss: 0.3736, val_loss: 0.3667, val_acc: 0.9490\n",
      "Epoch [47], train_loss: 0.3805, val_loss: 0.3812, val_acc: 0.9290\n",
      "Epoch [48], train_loss: 0.3799, val_loss: 0.3884, val_acc: 0.9240\n",
      "Epoch [49], train_loss: 0.3700, val_loss: 0.3694, val_acc: 0.9450\n"
     ]
    }
   ],
   "source": [
    "#reproduire le meilleur modele\n",
    "#data augmentation et dropout + Adam optimizer \n",
    "num_epochs = 50 #nous aurions pu mettre plus pour un meilleur apprentissage\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 1e-4\n",
    "history2, model2 = MediumFit(num_epochs, lr, model2, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "394df452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ConvNet                                  --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       896\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─MaxPool2d: 2-3                    --\n",
       "│    └─Conv2d: 2-4                       18,496\n",
       "│    └─ReLU: 2-5                         --\n",
       "│    └─MaxPool2d: 2-6                    --\n",
       "│    └─Conv2d: 2-7                       73,856\n",
       "│    └─ReLU: 2-8                         --\n",
       "│    └─MaxPool2d: 2-9                    --\n",
       "│    └─Conv2d: 2-10                      147,584\n",
       "│    └─ReLU: 2-11                        --\n",
       "│    └─MaxPool2d: 2-12                   --\n",
       "│    └─Flatten: 2-13                     --\n",
       "│    └─Dropout: 2-14                     --\n",
       "│    └─Linear: 2-15                      3,211,776\n",
       "│    └─ReLU: 2-16                        --\n",
       "│    └─Linear: 2-17                      1,026\n",
       "│    └─Sigmoid: 2-18                     --\n",
       "=================================================================\n",
       "Total params: 3,453,634\n",
       "Trainable params: 3,453,634\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ef48e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde du modele \n",
    "torch.save(model2.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82500f",
   "metadata": {},
   "source": [
    "# Fine tuning modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3a13d",
   "metadata": {},
   "source": [
    "## resnet50 modele pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a2a25b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sibghi\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sibghi\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#importation de resnet50 pretrained\n",
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c92449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the parameters to avoid backpropagation through them\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create a new sequential model\n",
    "classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048, 2),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "# Replace the last layer of the pre-trained model with our classifier\n",
    "resnet50.fc = classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cb5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(resnet50,(3,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f79c463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4679, grad_fn=<NllLossBackward0>)\n",
      "1 tensor(0.4983, grad_fn=<NllLossBackward0>)\n",
      "2 tensor(0.4722, grad_fn=<NllLossBackward0>)\n",
      "3 tensor(0.4294, grad_fn=<NllLossBackward0>)\n",
      "4 tensor(0.4440, grad_fn=<NllLossBackward0>)\n",
      "5 tensor(0.4526, grad_fn=<NllLossBackward0>)\n",
      "6 tensor(0.3516, grad_fn=<NllLossBackward0>)\n",
      "7 tensor(0.5136, grad_fn=<NllLossBackward0>)\n",
      "8 tensor(0.3968, grad_fn=<NllLossBackward0>)\n",
      "9 tensor(0.4673, grad_fn=<NllLossBackward0>)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#apprentissage du modele resnet50 + derniere couche changee \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(resnet50.parameters(), lr=1e-4)\n",
    "model = fit_CNN(resnet50, train_dl, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb795d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde du modele resnet50 + derniere couche changee\n",
    "torch.save(model.state_dict(), \"resnet50_coucheChange.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f3fab",
   "metadata": {},
   "source": [
    "## alexnet modele pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef631b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sam\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#importation de alexnet pretrained\n",
    "alexnet = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "277e261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the parameters to avoid backpropagation through them\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "alexnet.classifier[-1].requires_grad = True\n",
    "\n",
    "# Create a new sequential model\n",
    "classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 2),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "# Replace the last layer of the pre-trained model with our classifier\n",
    "alexnet.classifier[-1] = classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2aaaa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 36, 36]          23,296\n",
      "              ReLU-2           [-1, 64, 36, 36]               0\n",
      "         MaxPool2d-3           [-1, 64, 17, 17]               0\n",
      "            Conv2d-4          [-1, 192, 17, 17]         307,392\n",
      "              ReLU-5          [-1, 192, 17, 17]               0\n",
      "         MaxPool2d-6            [-1, 192, 8, 8]               0\n",
      "            Conv2d-7            [-1, 384, 8, 8]         663,936\n",
      "              ReLU-8            [-1, 384, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 8, 8]         884,992\n",
      "             ReLU-10            [-1, 256, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-12            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-13            [-1, 256, 3, 3]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "          Flatten-21                 [-1, 4096]               0\n",
      "          Dropout-22                 [-1, 4096]               0\n",
      "           Linear-23                    [-1, 2]           8,194\n",
      "          Sigmoid-24                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 57,012,034\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 57,003,840\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 3.60\n",
      "Params size (MB): 217.48\n",
      "Estimated Total Size (MB): 221.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(alexnet,(3,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173187cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apprentissage du modele alexnet + derniere couche changee \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(alexnet.parameters(), lr=1e-4)\n",
    "model2 = fit_CNN(alexnet, train_dl, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe522d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde du modele alexnet + derniere couche changee\n",
    "torch.save(model2.state_dict(), \"alexnet_coucheChange.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985ad2e",
   "metadata": {},
   "source": [
    "## wide_resnet50_2 modele pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9ff27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sibghi\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sibghi\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to C:\\Users\\sibghi/.cache\\torch\\hub\\checkpoints\\wide_resnet50_2-95faca4d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f053b76fffc41f7b11eea5c00631113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/132M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ff2b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_resnet50_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979ec3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in wide_resnet50_2.parameters():\n",
    "    param.requires_grad = False\n",
    "        \n",
    "        \n",
    "wide_resnet50_2.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048, 2),\n",
    "            nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb22ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 75, 75]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 75, 75]             128\n",
      "              ReLU-3           [-1, 64, 75, 75]               0\n",
      "         MaxPool2d-4           [-1, 64, 38, 38]               0\n",
      "            Conv2d-5          [-1, 128, 38, 38]           8,192\n",
      "       BatchNorm2d-6          [-1, 128, 38, 38]             256\n",
      "              ReLU-7          [-1, 128, 38, 38]               0\n",
      "            Conv2d-8          [-1, 128, 38, 38]         147,456\n",
      "       BatchNorm2d-9          [-1, 128, 38, 38]             256\n",
      "             ReLU-10          [-1, 128, 38, 38]               0\n",
      "           Conv2d-11          [-1, 256, 38, 38]          32,768\n",
      "      BatchNorm2d-12          [-1, 256, 38, 38]             512\n",
      "           Conv2d-13          [-1, 256, 38, 38]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 38, 38]             512\n",
      "             ReLU-15          [-1, 256, 38, 38]               0\n",
      "       Bottleneck-16          [-1, 256, 38, 38]               0\n",
      "           Conv2d-17          [-1, 128, 38, 38]          32,768\n",
      "      BatchNorm2d-18          [-1, 128, 38, 38]             256\n",
      "             ReLU-19          [-1, 128, 38, 38]               0\n",
      "           Conv2d-20          [-1, 128, 38, 38]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 38, 38]             256\n",
      "             ReLU-22          [-1, 128, 38, 38]               0\n",
      "           Conv2d-23          [-1, 256, 38, 38]          32,768\n",
      "      BatchNorm2d-24          [-1, 256, 38, 38]             512\n",
      "             ReLU-25          [-1, 256, 38, 38]               0\n",
      "       Bottleneck-26          [-1, 256, 38, 38]               0\n",
      "           Conv2d-27          [-1, 128, 38, 38]          32,768\n",
      "      BatchNorm2d-28          [-1, 128, 38, 38]             256\n",
      "             ReLU-29          [-1, 128, 38, 38]               0\n",
      "           Conv2d-30          [-1, 128, 38, 38]         147,456\n",
      "      BatchNorm2d-31          [-1, 128, 38, 38]             256\n",
      "             ReLU-32          [-1, 128, 38, 38]               0\n",
      "           Conv2d-33          [-1, 256, 38, 38]          32,768\n",
      "      BatchNorm2d-34          [-1, 256, 38, 38]             512\n",
      "             ReLU-35          [-1, 256, 38, 38]               0\n",
      "       Bottleneck-36          [-1, 256, 38, 38]               0\n",
      "           Conv2d-37          [-1, 256, 38, 38]          65,536\n",
      "      BatchNorm2d-38          [-1, 256, 38, 38]             512\n",
      "             ReLU-39          [-1, 256, 38, 38]               0\n",
      "           Conv2d-40          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-41          [-1, 256, 19, 19]             512\n",
      "             ReLU-42          [-1, 256, 19, 19]               0\n",
      "           Conv2d-43          [-1, 512, 19, 19]         131,072\n",
      "      BatchNorm2d-44          [-1, 512, 19, 19]           1,024\n",
      "           Conv2d-45          [-1, 512, 19, 19]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 19, 19]           1,024\n",
      "             ReLU-47          [-1, 512, 19, 19]               0\n",
      "       Bottleneck-48          [-1, 512, 19, 19]               0\n",
      "           Conv2d-49          [-1, 256, 19, 19]         131,072\n",
      "      BatchNorm2d-50          [-1, 256, 19, 19]             512\n",
      "             ReLU-51          [-1, 256, 19, 19]               0\n",
      "           Conv2d-52          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-53          [-1, 256, 19, 19]             512\n",
      "             ReLU-54          [-1, 256, 19, 19]               0\n",
      "           Conv2d-55          [-1, 512, 19, 19]         131,072\n",
      "      BatchNorm2d-56          [-1, 512, 19, 19]           1,024\n",
      "             ReLU-57          [-1, 512, 19, 19]               0\n",
      "       Bottleneck-58          [-1, 512, 19, 19]               0\n",
      "           Conv2d-59          [-1, 256, 19, 19]         131,072\n",
      "      BatchNorm2d-60          [-1, 256, 19, 19]             512\n",
      "             ReLU-61          [-1, 256, 19, 19]               0\n",
      "           Conv2d-62          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-63          [-1, 256, 19, 19]             512\n",
      "             ReLU-64          [-1, 256, 19, 19]               0\n",
      "           Conv2d-65          [-1, 512, 19, 19]         131,072\n",
      "      BatchNorm2d-66          [-1, 512, 19, 19]           1,024\n",
      "             ReLU-67          [-1, 512, 19, 19]               0\n",
      "       Bottleneck-68          [-1, 512, 19, 19]               0\n",
      "           Conv2d-69          [-1, 256, 19, 19]         131,072\n",
      "      BatchNorm2d-70          [-1, 256, 19, 19]             512\n",
      "             ReLU-71          [-1, 256, 19, 19]               0\n",
      "           Conv2d-72          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 19, 19]             512\n",
      "             ReLU-74          [-1, 256, 19, 19]               0\n",
      "           Conv2d-75          [-1, 512, 19, 19]         131,072\n",
      "      BatchNorm2d-76          [-1, 512, 19, 19]           1,024\n",
      "             ReLU-77          [-1, 512, 19, 19]               0\n",
      "       Bottleneck-78          [-1, 512, 19, 19]               0\n",
      "           Conv2d-79          [-1, 512, 19, 19]         262,144\n",
      "      BatchNorm2d-80          [-1, 512, 19, 19]           1,024\n",
      "             ReLU-81          [-1, 512, 19, 19]               0\n",
      "           Conv2d-82          [-1, 512, 10, 10]       2,359,296\n",
      "      BatchNorm2d-83          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-84          [-1, 512, 10, 10]               0\n",
      "           Conv2d-85         [-1, 1024, 10, 10]         524,288\n",
      "      BatchNorm2d-86         [-1, 1024, 10, 10]           2,048\n",
      "           Conv2d-87         [-1, 1024, 10, 10]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 10, 10]           2,048\n",
      "             ReLU-89         [-1, 1024, 10, 10]               0\n",
      "       Bottleneck-90         [-1, 1024, 10, 10]               0\n",
      "           Conv2d-91          [-1, 512, 10, 10]         524,288\n",
      "      BatchNorm2d-92          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-93          [-1, 512, 10, 10]               0\n",
      "           Conv2d-94          [-1, 512, 10, 10]       2,359,296\n",
      "      BatchNorm2d-95          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-96          [-1, 512, 10, 10]               0\n",
      "           Conv2d-97         [-1, 1024, 10, 10]         524,288\n",
      "      BatchNorm2d-98         [-1, 1024, 10, 10]           2,048\n",
      "             ReLU-99         [-1, 1024, 10, 10]               0\n",
      "      Bottleneck-100         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-101          [-1, 512, 10, 10]         524,288\n",
      "     BatchNorm2d-102          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-103          [-1, 512, 10, 10]               0\n",
      "          Conv2d-104          [-1, 512, 10, 10]       2,359,296\n",
      "     BatchNorm2d-105          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-106          [-1, 512, 10, 10]               0\n",
      "          Conv2d-107         [-1, 1024, 10, 10]         524,288\n",
      "     BatchNorm2d-108         [-1, 1024, 10, 10]           2,048\n",
      "            ReLU-109         [-1, 1024, 10, 10]               0\n",
      "      Bottleneck-110         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-111          [-1, 512, 10, 10]         524,288\n",
      "     BatchNorm2d-112          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-113          [-1, 512, 10, 10]               0\n",
      "          Conv2d-114          [-1, 512, 10, 10]       2,359,296\n",
      "     BatchNorm2d-115          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-116          [-1, 512, 10, 10]               0\n",
      "          Conv2d-117         [-1, 1024, 10, 10]         524,288\n",
      "     BatchNorm2d-118         [-1, 1024, 10, 10]           2,048\n",
      "            ReLU-119         [-1, 1024, 10, 10]               0\n",
      "      Bottleneck-120         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-121          [-1, 512, 10, 10]         524,288\n",
      "     BatchNorm2d-122          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-123          [-1, 512, 10, 10]               0\n",
      "          Conv2d-124          [-1, 512, 10, 10]       2,359,296\n",
      "     BatchNorm2d-125          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-126          [-1, 512, 10, 10]               0\n",
      "          Conv2d-127         [-1, 1024, 10, 10]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 10, 10]           2,048\n",
      "            ReLU-129         [-1, 1024, 10, 10]               0\n",
      "      Bottleneck-130         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-131          [-1, 512, 10, 10]         524,288\n",
      "     BatchNorm2d-132          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-133          [-1, 512, 10, 10]               0\n",
      "          Conv2d-134          [-1, 512, 10, 10]       2,359,296\n",
      "     BatchNorm2d-135          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-136          [-1, 512, 10, 10]               0\n",
      "          Conv2d-137         [-1, 1024, 10, 10]         524,288\n",
      "     BatchNorm2d-138         [-1, 1024, 10, 10]           2,048\n",
      "            ReLU-139         [-1, 1024, 10, 10]               0\n",
      "      Bottleneck-140         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-141         [-1, 1024, 10, 10]       1,048,576\n",
      "     BatchNorm2d-142         [-1, 1024, 10, 10]           2,048\n",
      "            ReLU-143         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-144           [-1, 1024, 5, 5]       9,437,184\n",
      "     BatchNorm2d-145           [-1, 1024, 5, 5]           2,048\n",
      "            ReLU-146           [-1, 1024, 5, 5]               0\n",
      "          Conv2d-147           [-1, 2048, 5, 5]       2,097,152\n",
      "     BatchNorm2d-148           [-1, 2048, 5, 5]           4,096\n",
      "          Conv2d-149           [-1, 2048, 5, 5]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 5, 5]           4,096\n",
      "            ReLU-151           [-1, 2048, 5, 5]               0\n",
      "      Bottleneck-152           [-1, 2048, 5, 5]               0\n",
      "          Conv2d-153           [-1, 1024, 5, 5]       2,097,152\n",
      "     BatchNorm2d-154           [-1, 1024, 5, 5]           2,048\n",
      "            ReLU-155           [-1, 1024, 5, 5]               0\n",
      "          Conv2d-156           [-1, 1024, 5, 5]       9,437,184\n",
      "     BatchNorm2d-157           [-1, 1024, 5, 5]           2,048\n",
      "            ReLU-158           [-1, 1024, 5, 5]               0\n",
      "          Conv2d-159           [-1, 2048, 5, 5]       2,097,152\n",
      "     BatchNorm2d-160           [-1, 2048, 5, 5]           4,096\n",
      "            ReLU-161           [-1, 2048, 5, 5]               0\n",
      "      Bottleneck-162           [-1, 2048, 5, 5]               0\n",
      "          Conv2d-163           [-1, 1024, 5, 5]       2,097,152\n",
      "     BatchNorm2d-164           [-1, 1024, 5, 5]           2,048\n",
      "            ReLU-165           [-1, 1024, 5, 5]               0\n",
      "          Conv2d-166           [-1, 1024, 5, 5]       9,437,184\n",
      "     BatchNorm2d-167           [-1, 1024, 5, 5]           2,048\n",
      "            ReLU-168           [-1, 1024, 5, 5]               0\n",
      "          Conv2d-169           [-1, 2048, 5, 5]       2,097,152\n",
      "     BatchNorm2d-170           [-1, 2048, 5, 5]           4,096\n",
      "            ReLU-171           [-1, 2048, 5, 5]               0\n",
      "      Bottleneck-172           [-1, 2048, 5, 5]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "         Flatten-174                 [-1, 2048]               0\n",
      "         Dropout-175                 [-1, 2048]               0\n",
      "          Linear-176                    [-1, 2]           4,098\n",
      "         Sigmoid-177                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 66,838,338\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 66,834,240\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 170.69\n",
      "Params size (MB): 254.97\n",
      "Estimated Total Size (MB): 425.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(wide_resnet50_2,(3,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c9563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.5151, grad_fn=<NllLossBackward0>)\n",
      "1 tensor(0.4733, grad_fn=<NllLossBackward0>)\n",
      "2 tensor(0.5068, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(wide_resnet50_2.parameters(), lr=1e-4)\n",
    "model3 = fit_CNN(wide_resnet50_2, train_dl, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610689da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde du modele alexnet + derniere couche changee\n",
    "torch.save(model3.state_dict(), \"wide_resnet50_2_coucheChange.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb5e6e",
   "metadata": {},
   "source": [
    "## Test du modèle sur les données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b71190cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 92 %\n"
     ]
    }
   ],
   "source": [
    "#Test du model resnet50 sur les donnees de validation \n",
    "val_pretrainresnet50 = val_CNN(model,val_dl) #92% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test du model alexnet sur les donnees de validation \n",
    "val_pretrainvgg19 = val_CNN(model2,val_dl) #89% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2827a",
   "metadata": {},
   "source": [
    "# Création d'un CNN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c819e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(),transforms.Resize((150,150)), transforms.Pad(2)])\n",
    "\n",
    "#Train\n",
    "train = datasets.ImageFolder(\"train_another\",transform = trans)\n",
    "\n",
    "#Validation\n",
    "validation = datasets.ImageFolder(\"validation_another\",transform = trans)\n",
    "\n",
    "#train loader\n",
    "train_loader = torch.utils.data.DataLoader(train, 20, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "\n",
    "#test loader\n",
    "val_loader = torch.utils.data.DataLoader(validation, 20, shuffle = False, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d02fc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewModel = NewCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f225c317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.6620, val_loss: 0.6543, val_acc: 0.6800\n",
      "Epoch [1], train_loss: 0.5475, val_loss: 1.2604, val_acc: 0.0260\n",
      "Epoch [2], train_loss: 0.5495, val_loss: 0.4475, val_acc: 0.8650\n",
      "Epoch [3], train_loss: 0.4929, val_loss: 0.4868, val_acc: 0.8230\n",
      "Epoch [4], train_loss: 0.4544, val_loss: 0.5137, val_acc: 0.7980\n",
      "Epoch [5], train_loss: 0.4254, val_loss: 0.3644, val_acc: 0.9440\n",
      "Epoch [6], train_loss: 0.4346, val_loss: 0.4610, val_acc: 0.8540\n",
      "Epoch [7], train_loss: 0.4104, val_loss: 0.3898, val_acc: 0.9220\n",
      "Epoch [8], train_loss: 0.4208, val_loss: 0.4063, val_acc: 0.9160\n",
      "Epoch [9], train_loss: 0.4087, val_loss: 0.3737, val_acc: 0.9390\n",
      "Epoch [10], train_loss: 0.4122, val_loss: 0.4080, val_acc: 0.9140\n",
      "Epoch [11], train_loss: 0.4028, val_loss: 0.3878, val_acc: 0.9250\n",
      "Epoch [12], train_loss: 0.3960, val_loss: 0.3443, val_acc: 0.9690\n",
      "Epoch [13], train_loss: 0.4088, val_loss: 0.3928, val_acc: 0.9240\n",
      "Epoch [14], train_loss: 0.3876, val_loss: 0.4391, val_acc: 0.8770\n",
      "Epoch [15], train_loss: 0.3936, val_loss: 0.3365, val_acc: 0.9760\n",
      "Epoch [16], train_loss: 0.3962, val_loss: 0.3863, val_acc: 0.9290\n",
      "Epoch [17], train_loss: 0.3852, val_loss: 0.3496, val_acc: 0.9670\n",
      "Epoch [18], train_loss: 0.3908, val_loss: 0.3347, val_acc: 0.9850\n",
      "Epoch [19], train_loss: 0.4052, val_loss: 0.3598, val_acc: 0.9620\n",
      "Epoch [20], train_loss: 0.3883, val_loss: 0.3877, val_acc: 0.9270\n",
      "Epoch [21], train_loss: 0.3910, val_loss: 0.3318, val_acc: 0.9860\n",
      "Epoch [22], train_loss: 0.3805, val_loss: 0.3653, val_acc: 0.9530\n",
      "Epoch [23], train_loss: 0.3713, val_loss: 0.4784, val_acc: 0.8360\n",
      "Epoch [24], train_loss: 0.3883, val_loss: 0.3954, val_acc: 0.9110\n",
      "Epoch [25], train_loss: 0.3735, val_loss: 0.3549, val_acc: 0.9560\n",
      "Epoch [26], train_loss: 0.3733, val_loss: 0.3317, val_acc: 0.9830\n",
      "Epoch [27], train_loss: 0.3768, val_loss: 0.3651, val_acc: 0.9450\n",
      "Epoch [28], train_loss: 0.3736, val_loss: 0.3735, val_acc: 0.9410\n",
      "Epoch [29], train_loss: 0.3664, val_loss: 0.3217, val_acc: 0.9940\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = MediumFit(num_epochs, lr, NewModel, train_loader, val_loader, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf765c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(history.state_dict(), \"ModelPerso.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss and accuracy for detection overfitting (30 epochs)\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history['acc']\n",
    "val_acc = history['val_acc']\n",
    "loss = history['train_loss']\n",
    "val_loss = history['val_loss']\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy with ReLU')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title('Training and validation loss with ReLU')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6156066da90931b679949b232dacbbde05a7077b615e164ae87be248eaed4987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
