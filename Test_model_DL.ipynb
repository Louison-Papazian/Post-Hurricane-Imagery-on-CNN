{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38c6a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sibghi\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sibghi\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5fee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4286e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/sibghi/Downloads/Post-hurricane'\n",
    "\n",
    "train = datasets.ImageFolder(data_dir + \"/train_another\",transform = transforms.Compose([\n",
    "    transforms.Resize((150,150)),transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "#Validation\n",
    "validation = datasets.ImageFolder(data_dir + \"/validation_another\",transform = transforms.Compose([\n",
    "    transforms.Resize((150,150)),transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a34b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement en DataLoader avec batch 128 pour éviter les crashs en entrainement et shuffle\n",
    "#pour mélanger les batchs à chaque étape de l'entrainement\n",
    "train_dl = torch.utils.data.DataLoader(train, 20, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "\n",
    "val_dl = torch.utils.data.DataLoader(validation, 20, shuffle = True,num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a7ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = 'C:/Users/sibghi/Downloads/Post-hurricane'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e44f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_damage_dir = original_dataset_dir + '/train_another/damage'\n",
    "validation_damage_dir = original_dataset_dir + '/validation_another/damage'\n",
    "test_damage_dir = original_dataset_dir + '/test_another/damage'\n",
    "\n",
    "train_nodamage_dir = original_dataset_dir + '/train_another/no_damage'\n",
    "validation_nodamage_dir = original_dataset_dir + '/validation_another/no_damage'\n",
    "test_nodamage_dir = original_dataset_dir + '/test_another/no_damage'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0398e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training damage images:  5000\n",
      "total validation damage images:  1000\n",
      "total test damage images:  8000\n",
      "total training no damage images:  5000\n",
      "total validation no damage images:  1000\n",
      "total test no damage images:  1000\n"
     ]
    }
   ],
   "source": [
    "print('total training damage images: ',len(os.listdir(train_damage_dir)))\n",
    "print('total validation damage images: ',len(os.listdir(validation_damage_dir)))\n",
    "print('total test damage images: ',len(os.listdir(test_damage_dir)))\n",
    "\n",
    "print('total training no damage images: ',len(os.listdir(train_nodamage_dir)))\n",
    "print('total validation no damage images: ',len(os.listdir(validation_nodamage_dir)))\n",
    "print('total test no damage images: ',len(os.listdir(test_nodamage_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09615d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70be1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*7*7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d9c32f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "    (13): Linear(in_features=6272, out_features=512, bias=True)\n",
       "    (14): ReLU()\n",
       "    (15): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (16): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7cce659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    step = 0\n",
    "    outputs = []\n",
    "    for batch in val_loader :\n",
    "        step += 1\n",
    "        outputs.append(model.validation_step(batch))\n",
    "        if step == 50:\n",
    "                break \n",
    "                \n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        step = 0\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            step += 1\n",
    "            if step == 100:\n",
    "                break \n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20033898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_epochs = 50\n",
    "#opt_func = torch.optim.RMSprop\n",
    "#lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "#history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225e06b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reproduire le 1er modele \n",
    "#data augmentation + RMSprop optimizer \n",
    "num_epochs = 50\n",
    "opt_func = torch.optim.RMSprop\n",
    "lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4e29a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128*7*7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "model2 = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85def551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.6795, val_loss: 0.6194, val_acc: 0.7420\n",
      "Epoch [1], train_loss: 0.5881, val_loss: 0.5261, val_acc: 0.7940\n",
      "Epoch [2], train_loss: 0.5428, val_loss: 0.5441, val_acc: 0.7520\n",
      "Epoch [3], train_loss: 0.5307, val_loss: 0.5135, val_acc: 0.8010\n",
      "Epoch [4], train_loss: 0.5078, val_loss: 0.4916, val_acc: 0.8120\n",
      "Epoch [5], train_loss: 0.4985, val_loss: 0.4643, val_acc: 0.8470\n",
      "Epoch [6], train_loss: 0.4549, val_loss: 0.4546, val_acc: 0.8570\n",
      "Epoch [7], train_loss: 0.4654, val_loss: 0.4065, val_acc: 0.9070\n",
      "Epoch [8], train_loss: 0.4244, val_loss: 0.4425, val_acc: 0.8690\n",
      "Epoch [9], train_loss: 0.4300, val_loss: 0.4072, val_acc: 0.9100\n",
      "Epoch [10], train_loss: 0.4220, val_loss: 0.4077, val_acc: 0.9120\n",
      "Epoch [11], train_loss: 0.4097, val_loss: 0.4220, val_acc: 0.8870\n",
      "Epoch [12], train_loss: 0.4142, val_loss: 0.4049, val_acc: 0.9060\n",
      "Epoch [13], train_loss: 0.4108, val_loss: 0.4261, val_acc: 0.8840\n",
      "Epoch [14], train_loss: 0.4106, val_loss: 0.3969, val_acc: 0.9220\n",
      "Epoch [15], train_loss: 0.4079, val_loss: 0.3944, val_acc: 0.9170\n",
      "Epoch [16], train_loss: 0.4078, val_loss: 0.4154, val_acc: 0.8890\n",
      "Epoch [17], train_loss: 0.4093, val_loss: 0.3940, val_acc: 0.9140\n",
      "Epoch [18], train_loss: 0.4001, val_loss: 0.3887, val_acc: 0.9160\n",
      "Epoch [19], train_loss: 0.3960, val_loss: 0.3934, val_acc: 0.9140\n",
      "Epoch [20], train_loss: 0.3987, val_loss: 0.4125, val_acc: 0.8980\n",
      "Epoch [21], train_loss: 0.3918, val_loss: 0.4044, val_acc: 0.9110\n",
      "Epoch [22], train_loss: 0.4018, val_loss: 0.4095, val_acc: 0.9050\n",
      "Epoch [23], train_loss: 0.3973, val_loss: 0.3894, val_acc: 0.9190\n",
      "Epoch [24], train_loss: 0.3863, val_loss: 0.4019, val_acc: 0.9080\n",
      "Epoch [25], train_loss: 0.3883, val_loss: 0.4079, val_acc: 0.8990\n",
      "Epoch [26], train_loss: 0.3898, val_loss: 0.3898, val_acc: 0.9190\n",
      "Epoch [27], train_loss: 0.3951, val_loss: 0.3873, val_acc: 0.9240\n",
      "Epoch [28], train_loss: 0.4035, val_loss: 0.3869, val_acc: 0.9240\n",
      "Epoch [29], train_loss: 0.3880, val_loss: 0.3917, val_acc: 0.9190\n",
      "Epoch [30], train_loss: 0.3973, val_loss: 0.3735, val_acc: 0.9380\n",
      "Epoch [31], train_loss: 0.3905, val_loss: 0.3819, val_acc: 0.9310\n",
      "Epoch [32], train_loss: 0.3887, val_loss: 0.3836, val_acc: 0.9270\n",
      "Epoch [33], train_loss: 0.3898, val_loss: 0.4253, val_acc: 0.8800\n",
      "Epoch [34], train_loss: 0.3870, val_loss: 0.3811, val_acc: 0.9270\n",
      "Epoch [35], train_loss: 0.3849, val_loss: 0.3809, val_acc: 0.9310\n",
      "Epoch [36], train_loss: 0.3845, val_loss: 0.3812, val_acc: 0.9320\n",
      "Epoch [37], train_loss: 0.3935, val_loss: 0.3842, val_acc: 0.9290\n",
      "Epoch [38], train_loss: 0.3899, val_loss: 0.4001, val_acc: 0.9060\n",
      "Epoch [39], train_loss: 0.3799, val_loss: 0.3947, val_acc: 0.9120\n",
      "Epoch [40], train_loss: 0.3800, val_loss: 0.3707, val_acc: 0.9390\n",
      "Epoch [41], train_loss: 0.3693, val_loss: 0.3947, val_acc: 0.9170\n",
      "Epoch [42], train_loss: 0.3828, val_loss: 0.4279, val_acc: 0.8880\n",
      "Epoch [43], train_loss: 0.3906, val_loss: 0.3748, val_acc: 0.9410\n",
      "Epoch [44], train_loss: 0.3789, val_loss: 0.3710, val_acc: 0.9390\n",
      "Epoch [45], train_loss: 0.3812, val_loss: 0.3664, val_acc: 0.9470\n",
      "Epoch [46], train_loss: 0.3736, val_loss: 0.3667, val_acc: 0.9490\n",
      "Epoch [47], train_loss: 0.3805, val_loss: 0.3812, val_acc: 0.9290\n",
      "Epoch [48], train_loss: 0.3799, val_loss: 0.3884, val_acc: 0.9240\n",
      "Epoch [49], train_loss: 0.3700, val_loss: 0.3694, val_acc: 0.9450\n"
     ]
    }
   ],
   "source": [
    "#reproduire le meilleur modele\n",
    "#data augmentation et dropout + Adam optimizer \n",
    "num_epochs = 50\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 1e-4\n",
    "history2, model2 = fit(num_epochs, lr, model2, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78ae20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchinfo\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85455be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ConvNet                                  --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       896\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─MaxPool2d: 2-3                    --\n",
       "│    └─Conv2d: 2-4                       18,496\n",
       "│    └─ReLU: 2-5                         --\n",
       "│    └─MaxPool2d: 2-6                    --\n",
       "│    └─Conv2d: 2-7                       73,856\n",
       "│    └─ReLU: 2-8                         --\n",
       "│    └─MaxPool2d: 2-9                    --\n",
       "│    └─Conv2d: 2-10                      147,584\n",
       "│    └─ReLU: 2-11                        --\n",
       "│    └─MaxPool2d: 2-12                   --\n",
       "│    └─Flatten: 2-13                     --\n",
       "│    └─Dropout: 2-14                     --\n",
       "│    └─Linear: 2-15                      3,211,776\n",
       "│    └─ReLU: 2-16                        --\n",
       "│    └─Linear: 2-17                      1,026\n",
       "│    └─Sigmoid: 2-18                     --\n",
       "=================================================================\n",
       "Total params: 3,453,634\n",
       "Trainable params: 3,453,634\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc56b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), \"C:/Users/sibghi/Téléchargements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2703e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "vgg19 = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83c6eca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74821982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model weights\n",
    "for param in vgg19.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Add on classifier in the last layer \n",
    "vgg19.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(512, 2),\n",
    "                      nn.Sigmoid())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a7f934a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19.classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d372bda3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VGG' object has no attribute 'training_step'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m opt_func \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam\n\u001b[0;32m      5\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n\u001b[1;32m----> 6\u001b[0m history3, model3 \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvgg19\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[0;32m     28\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m---> 30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m(batch)\n\u001b[0;32m     31\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     32\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1269\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VGG' object has no attribute 'training_step'"
     ]
    }
   ],
   "source": [
    "#reproduire le meilleur modele\n",
    "#pretrainmodel with sequential in last layer + Adam optimizer \n",
    "num_epochs = 30\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 1e-4\n",
    "history3, model3 = fit(num_epochs, lr, vgg19, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06157844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sibghi\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\sibghi/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edab8737389148f1b70425fed1b86294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13619ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ResNet                                   --\n",
       "├─Conv2d: 1-1                            (9,408)\n",
       "├─BatchNorm2d: 1-2                       (128)\n",
       "├─ReLU: 1-3                              --\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Sequential: 1-5                        --\n",
       "│    └─Bottleneck: 2-1                   --\n",
       "│    │    └─Conv2d: 3-1                  (4,096)\n",
       "│    │    └─BatchNorm2d: 3-2             (128)\n",
       "│    │    └─Conv2d: 3-3                  (36,864)\n",
       "│    │    └─BatchNorm2d: 3-4             (128)\n",
       "│    │    └─Conv2d: 3-5                  (16,384)\n",
       "│    │    └─BatchNorm2d: 3-6             (512)\n",
       "│    │    └─ReLU: 3-7                    --\n",
       "│    │    └─Sequential: 3-8              (16,896)\n",
       "│    └─Bottleneck: 2-2                   --\n",
       "│    │    └─Conv2d: 3-9                  (16,384)\n",
       "│    │    └─BatchNorm2d: 3-10            (128)\n",
       "│    │    └─Conv2d: 3-11                 (36,864)\n",
       "│    │    └─BatchNorm2d: 3-12            (128)\n",
       "│    │    └─Conv2d: 3-13                 (16,384)\n",
       "│    │    └─BatchNorm2d: 3-14            (512)\n",
       "│    │    └─ReLU: 3-15                   --\n",
       "│    └─Bottleneck: 2-3                   --\n",
       "│    │    └─Conv2d: 3-16                 (16,384)\n",
       "│    │    └─BatchNorm2d: 3-17            (128)\n",
       "│    │    └─Conv2d: 3-18                 (36,864)\n",
       "│    │    └─BatchNorm2d: 3-19            (128)\n",
       "│    │    └─Conv2d: 3-20                 (16,384)\n",
       "│    │    └─BatchNorm2d: 3-21            (512)\n",
       "│    │    └─ReLU: 3-22                   --\n",
       "├─Sequential: 1-6                        --\n",
       "│    └─Bottleneck: 2-4                   --\n",
       "│    │    └─Conv2d: 3-23                 (32,768)\n",
       "│    │    └─BatchNorm2d: 3-24            (256)\n",
       "│    │    └─Conv2d: 3-25                 (147,456)\n",
       "│    │    └─BatchNorm2d: 3-26            (256)\n",
       "│    │    └─Conv2d: 3-27                 (65,536)\n",
       "│    │    └─BatchNorm2d: 3-28            (1,024)\n",
       "│    │    └─ReLU: 3-29                   --\n",
       "│    │    └─Sequential: 3-30             (132,096)\n",
       "│    └─Bottleneck: 2-5                   --\n",
       "│    │    └─Conv2d: 3-31                 (65,536)\n",
       "│    │    └─BatchNorm2d: 3-32            (256)\n",
       "│    │    └─Conv2d: 3-33                 (147,456)\n",
       "│    │    └─BatchNorm2d: 3-34            (256)\n",
       "│    │    └─Conv2d: 3-35                 (65,536)\n",
       "│    │    └─BatchNorm2d: 3-36            (1,024)\n",
       "│    │    └─ReLU: 3-37                   --\n",
       "│    └─Bottleneck: 2-6                   --\n",
       "│    │    └─Conv2d: 3-38                 (65,536)\n",
       "│    │    └─BatchNorm2d: 3-39            (256)\n",
       "│    │    └─Conv2d: 3-40                 (147,456)\n",
       "│    │    └─BatchNorm2d: 3-41            (256)\n",
       "│    │    └─Conv2d: 3-42                 (65,536)\n",
       "│    │    └─BatchNorm2d: 3-43            (1,024)\n",
       "│    │    └─ReLU: 3-44                   --\n",
       "│    └─Bottleneck: 2-7                   --\n",
       "│    │    └─Conv2d: 3-45                 (65,536)\n",
       "│    │    └─BatchNorm2d: 3-46            (256)\n",
       "│    │    └─Conv2d: 3-47                 (147,456)\n",
       "│    │    └─BatchNorm2d: 3-48            (256)\n",
       "│    │    └─Conv2d: 3-49                 (65,536)\n",
       "│    │    └─BatchNorm2d: 3-50            (1,024)\n",
       "│    │    └─ReLU: 3-51                   --\n",
       "├─Sequential: 1-7                        --\n",
       "│    └─Bottleneck: 2-8                   --\n",
       "│    │    └─Conv2d: 3-52                 (131,072)\n",
       "│    │    └─BatchNorm2d: 3-53            (512)\n",
       "│    │    └─Conv2d: 3-54                 (589,824)\n",
       "│    │    └─BatchNorm2d: 3-55            (512)\n",
       "│    │    └─Conv2d: 3-56                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-57            (2,048)\n",
       "│    │    └─ReLU: 3-58                   --\n",
       "│    │    └─Sequential: 3-59             (526,336)\n",
       "│    └─Bottleneck: 2-9                   --\n",
       "│    │    └─Conv2d: 3-60                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-61            (512)\n",
       "│    │    └─Conv2d: 3-62                 (589,824)\n",
       "│    │    └─BatchNorm2d: 3-63            (512)\n",
       "│    │    └─Conv2d: 3-64                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-65            (2,048)\n",
       "│    │    └─ReLU: 3-66                   --\n",
       "│    └─Bottleneck: 2-10                  --\n",
       "│    │    └─Conv2d: 3-67                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-68            (512)\n",
       "│    │    └─Conv2d: 3-69                 (589,824)\n",
       "│    │    └─BatchNorm2d: 3-70            (512)\n",
       "│    │    └─Conv2d: 3-71                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-72            (2,048)\n",
       "│    │    └─ReLU: 3-73                   --\n",
       "│    └─Bottleneck: 2-11                  --\n",
       "│    │    └─Conv2d: 3-74                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-75            (512)\n",
       "│    │    └─Conv2d: 3-76                 (589,824)\n",
       "│    │    └─BatchNorm2d: 3-77            (512)\n",
       "│    │    └─Conv2d: 3-78                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-79            (2,048)\n",
       "│    │    └─ReLU: 3-80                   --\n",
       "│    └─Bottleneck: 2-12                  --\n",
       "│    │    └─Conv2d: 3-81                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-82            (512)\n",
       "│    │    └─Conv2d: 3-83                 (589,824)\n",
       "│    │    └─BatchNorm2d: 3-84            (512)\n",
       "│    │    └─Conv2d: 3-85                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-86            (2,048)\n",
       "│    │    └─ReLU: 3-87                   --\n",
       "│    └─Bottleneck: 2-13                  --\n",
       "│    │    └─Conv2d: 3-88                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-89            (512)\n",
       "│    │    └─Conv2d: 3-90                 (589,824)\n",
       "│    │    └─BatchNorm2d: 3-91            (512)\n",
       "│    │    └─Conv2d: 3-92                 (262,144)\n",
       "│    │    └─BatchNorm2d: 3-93            (2,048)\n",
       "│    │    └─ReLU: 3-94                   --\n",
       "├─Sequential: 1-8                        --\n",
       "│    └─Bottleneck: 2-14                  --\n",
       "│    │    └─Conv2d: 3-95                 (524,288)\n",
       "│    │    └─BatchNorm2d: 3-96            (1,024)\n",
       "│    │    └─Conv2d: 3-97                 (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-98            (1,024)\n",
       "│    │    └─Conv2d: 3-99                 (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-100           (4,096)\n",
       "│    │    └─ReLU: 3-101                  --\n",
       "│    │    └─Sequential: 3-102            (2,101,248)\n",
       "│    └─Bottleneck: 2-15                  --\n",
       "│    │    └─Conv2d: 3-103                (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-104           (1,024)\n",
       "│    │    └─Conv2d: 3-105                (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-106           (1,024)\n",
       "│    │    └─Conv2d: 3-107                (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-108           (4,096)\n",
       "│    │    └─ReLU: 3-109                  --\n",
       "│    └─Bottleneck: 2-16                  --\n",
       "│    │    └─Conv2d: 3-110                (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-111           (1,024)\n",
       "│    │    └─Conv2d: 3-112                (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-113           (1,024)\n",
       "│    │    └─Conv2d: 3-114                (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-115           (4,096)\n",
       "│    │    └─ReLU: 3-116                  --\n",
       "├─AdaptiveAvgPool2d: 1-9                 --\n",
       "├─Linear: 1-10                           (2,049,000)\n",
       "=================================================================\n",
       "Total params: 25,557,032\n",
       "Trainable params: 0\n",
       "Non-trainable params: 25,557,032\n",
       "================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c748519f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'inplace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m vgg19\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m      2\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m vgg19\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[0;32m      5\u001b[0m             nn\u001b[38;5;241m.\u001b[39mSigmoid())\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'inplace'"
     ]
    }
   ],
   "source": [
    "for param in vgg19.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vgg19.classifier = nn.Sequential(nn.Linear(512, 2),\n",
    "            nn.Sigmoid())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13a7e438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_base = resnet50.conv1 # remove the last maxpooling layer\n",
    "conv_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdc8ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.7.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb9d5445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\sibghi/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca226afdb8754372a8fd681c4a9bc552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# Initialize model\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "model = resnet50(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6464d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count,4,4,512))\n",
    "    labels = np.zeros(shape = (sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "                    directory, \n",
    "                    target_size = (150,150),\n",
    "                    batch_size = batch_size,\n",
    "                    class_mode = 'binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count: #generators yield data indefinitely\n",
    "            break                          #have to break after we have seen every image once\n",
    "    return features, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e39fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 10000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 2000)\n",
    "test_features, test_labels = extract_features(test_dir, 2000)\n",
    "#the extracted features are of shape (sample_count, 4, 4, 512), we must flatten them to (sample_count, 8192)\n",
    "train_features = np.reshape(train_features, (10000, 4*4*512))\n",
    "validation_features = np.reshape(validation_features, (2000, 4*4*512))\n",
    "test_features = np.reshape(test_features, (2000, 4*4*512))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
