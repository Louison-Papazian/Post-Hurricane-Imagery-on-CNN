{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5fee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c00727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a0f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/sibghi/Downloads/Post-hurricane'\n",
    "\n",
    "train = datasets.ImageFolder(data_dir + \"/train_another\",transform = transforms.Compose([\n",
    "    transforms.Resize((150,150)),transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "#Validation\n",
    "validation = datasets.ImageFolder(data_dir + \"/validation_another\",transform = transforms.Compose([\n",
    "    transforms.Resize((150,150)),transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "55f3eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement en DataLoader avec batch 128 pour éviter les crashs en entrainement et shuffle\n",
    "#pour mélanger les batchs à chaque étape de l'entrainement\n",
    "train_dl = torch.utils.data.DataLoader(train, 20, shuffle = True, num_workers = 0, pin_memory = True)\n",
    "\n",
    "val_dl = torch.utils.data.DataLoader(validation, 20, shuffle = True,num_workers = 0, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a7ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = 'C:/Users/sibghi/Downloads/Post-hurricane'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e44f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_damage_dir = original_dataset_dir + '/train_another/damage'\n",
    "validation_damage_dir = original_dataset_dir + '/validation_another/damage'\n",
    "test_damage_dir = original_dataset_dir + '/test_another/damage'\n",
    "\n",
    "train_nodamage_dir = original_dataset_dir + '/train_another/no_damage'\n",
    "validation_nodamage_dir = original_dataset_dir + '/validation_another/no_damage'\n",
    "test_nodamage_dir = original_dataset_dir + '/test_another/no_damage'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0398e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training damage images:  5000\n",
      "total validation damage images:  1000\n",
      "total test damage images:  8000\n",
      "total training no damage images:  5000\n",
      "total validation no damage images:  1000\n",
      "total test no damage images:  1000\n"
     ]
    }
   ],
   "source": [
    "print('total training damage images: ',len(os.listdir(train_damage_dir)))\n",
    "print('total validation damage images: ',len(os.listdir(validation_damage_dir)))\n",
    "print('total test damage images: ',len(os.listdir(test_damage_dir)))\n",
    "\n",
    "print('total training no damage images: ',len(os.listdir(train_nodamage_dir)))\n",
    "print('total validation no damage images: ',len(os.listdir(validation_nodamage_dir)))\n",
    "print('total test no damage images: ',len(os.listdir(test_nodamage_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09615d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70be1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*7*7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d9c32f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "    (13): Linear(in_features=6272, out_features=512, bias=True)\n",
       "    (14): ReLU()\n",
       "    (15): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (16): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7cce659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    step = 0\n",
    "    outputs = []\n",
    "    for batch in val_loader :\n",
    "        step += 1\n",
    "        outputs.append(model.validation_step(batch))\n",
    "        if step == 50:\n",
    "                break \n",
    "                \n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        step = 0\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            step += 1\n",
    "            if step == 100:\n",
    "                break \n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20033898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_epochs = 50\n",
    "#opt_func = torch.optim.RMSprop\n",
    "#lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "#history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd22524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reproduire le 1er modele \n",
    "#data augmentation + RMSprop optimizer \n",
    "num_epochs = 50\n",
    "opt_func = torch.optim.RMSprop\n",
    "lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b848a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cereation avec dropout \n",
    "class ConvNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size =(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128*7*7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "model2 = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c8f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.6795, val_loss: 0.6194, val_acc: 0.7420\n",
      "Epoch [1], train_loss: 0.5881, val_loss: 0.5261, val_acc: 0.7940\n",
      "Epoch [2], train_loss: 0.5428, val_loss: 0.5441, val_acc: 0.7520\n",
      "Epoch [3], train_loss: 0.5307, val_loss: 0.5135, val_acc: 0.8010\n",
      "Epoch [4], train_loss: 0.5078, val_loss: 0.4916, val_acc: 0.8120\n",
      "Epoch [5], train_loss: 0.4985, val_loss: 0.4643, val_acc: 0.8470\n",
      "Epoch [6], train_loss: 0.4549, val_loss: 0.4546, val_acc: 0.8570\n",
      "Epoch [7], train_loss: 0.4654, val_loss: 0.4065, val_acc: 0.9070\n",
      "Epoch [8], train_loss: 0.4244, val_loss: 0.4425, val_acc: 0.8690\n",
      "Epoch [9], train_loss: 0.4300, val_loss: 0.4072, val_acc: 0.9100\n",
      "Epoch [10], train_loss: 0.4220, val_loss: 0.4077, val_acc: 0.9120\n",
      "Epoch [11], train_loss: 0.4097, val_loss: 0.4220, val_acc: 0.8870\n",
      "Epoch [12], train_loss: 0.4142, val_loss: 0.4049, val_acc: 0.9060\n",
      "Epoch [13], train_loss: 0.4108, val_loss: 0.4261, val_acc: 0.8840\n",
      "Epoch [14], train_loss: 0.4106, val_loss: 0.3969, val_acc: 0.9220\n",
      "Epoch [15], train_loss: 0.4079, val_loss: 0.3944, val_acc: 0.9170\n",
      "Epoch [16], train_loss: 0.4078, val_loss: 0.4154, val_acc: 0.8890\n",
      "Epoch [17], train_loss: 0.4093, val_loss: 0.3940, val_acc: 0.9140\n",
      "Epoch [18], train_loss: 0.4001, val_loss: 0.3887, val_acc: 0.9160\n",
      "Epoch [19], train_loss: 0.3960, val_loss: 0.3934, val_acc: 0.9140\n",
      "Epoch [20], train_loss: 0.3987, val_loss: 0.4125, val_acc: 0.8980\n",
      "Epoch [21], train_loss: 0.3918, val_loss: 0.4044, val_acc: 0.9110\n",
      "Epoch [22], train_loss: 0.4018, val_loss: 0.4095, val_acc: 0.9050\n",
      "Epoch [23], train_loss: 0.3973, val_loss: 0.3894, val_acc: 0.9190\n",
      "Epoch [24], train_loss: 0.3863, val_loss: 0.4019, val_acc: 0.9080\n",
      "Epoch [25], train_loss: 0.3883, val_loss: 0.4079, val_acc: 0.8990\n",
      "Epoch [26], train_loss: 0.3898, val_loss: 0.3898, val_acc: 0.9190\n",
      "Epoch [27], train_loss: 0.3951, val_loss: 0.3873, val_acc: 0.9240\n",
      "Epoch [28], train_loss: 0.4035, val_loss: 0.3869, val_acc: 0.9240\n",
      "Epoch [29], train_loss: 0.3880, val_loss: 0.3917, val_acc: 0.9190\n",
      "Epoch [30], train_loss: 0.3973, val_loss: 0.3735, val_acc: 0.9380\n",
      "Epoch [31], train_loss: 0.3905, val_loss: 0.3819, val_acc: 0.9310\n",
      "Epoch [32], train_loss: 0.3887, val_loss: 0.3836, val_acc: 0.9270\n",
      "Epoch [33], train_loss: 0.3898, val_loss: 0.4253, val_acc: 0.8800\n",
      "Epoch [34], train_loss: 0.3870, val_loss: 0.3811, val_acc: 0.9270\n",
      "Epoch [35], train_loss: 0.3849, val_loss: 0.3809, val_acc: 0.9310\n",
      "Epoch [36], train_loss: 0.3845, val_loss: 0.3812, val_acc: 0.9320\n",
      "Epoch [37], train_loss: 0.3935, val_loss: 0.3842, val_acc: 0.9290\n",
      "Epoch [38], train_loss: 0.3899, val_loss: 0.4001, val_acc: 0.9060\n",
      "Epoch [39], train_loss: 0.3799, val_loss: 0.3947, val_acc: 0.9120\n",
      "Epoch [40], train_loss: 0.3800, val_loss: 0.3707, val_acc: 0.9390\n",
      "Epoch [41], train_loss: 0.3693, val_loss: 0.3947, val_acc: 0.9170\n",
      "Epoch [42], train_loss: 0.3828, val_loss: 0.4279, val_acc: 0.8880\n",
      "Epoch [43], train_loss: 0.3906, val_loss: 0.3748, val_acc: 0.9410\n",
      "Epoch [44], train_loss: 0.3789, val_loss: 0.3710, val_acc: 0.9390\n",
      "Epoch [45], train_loss: 0.3812, val_loss: 0.3664, val_acc: 0.9470\n",
      "Epoch [46], train_loss: 0.3736, val_loss: 0.3667, val_acc: 0.9490\n",
      "Epoch [47], train_loss: 0.3805, val_loss: 0.3812, val_acc: 0.9290\n",
      "Epoch [48], train_loss: 0.3799, val_loss: 0.3884, val_acc: 0.9240\n",
      "Epoch [49], train_loss: 0.3700, val_loss: 0.3694, val_acc: 0.9450\n"
     ]
    }
   ],
   "source": [
    "#reproduire le meilleur modele\n",
    "#data augmentation et dropout + Adam optimizer \n",
    "num_epochs = 50\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 1e-4\n",
    "history2, model2 = fit(num_epochs, lr, model2, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d39911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchinfo\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fdb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction pour tester les modeles pretrain sur validation\n",
    "def val_CNN(net, valLoader):\n",
    "    correct, total = 0, 0\n",
    "    predictions = []\n",
    "    net.eval()\n",
    "    for i, data in enumerate(valLoader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)    \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.append(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "394df452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ConvNet                                  --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       896\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─MaxPool2d: 2-3                    --\n",
       "│    └─Conv2d: 2-4                       18,496\n",
       "│    └─ReLU: 2-5                         --\n",
       "│    └─MaxPool2d: 2-6                    --\n",
       "│    └─Conv2d: 2-7                       73,856\n",
       "│    └─ReLU: 2-8                         --\n",
       "│    └─MaxPool2d: 2-9                    --\n",
       "│    └─Conv2d: 2-10                      147,584\n",
       "│    └─ReLU: 2-11                        --\n",
       "│    └─MaxPool2d: 2-12                   --\n",
       "│    └─Flatten: 2-13                     --\n",
       "│    └─Dropout: 2-14                     --\n",
       "│    └─Linear: 2-15                      3,211,776\n",
       "│    └─ReLU: 2-16                        --\n",
       "│    └─Linear: 2-17                      1,026\n",
       "│    └─Sigmoid: 2-18                     --\n",
       "=================================================================\n",
       "Total params: 3,453,634\n",
       "Trainable params: 3,453,634\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ef48e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "62d15154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "vgg19 = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3ca21af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
      "              ReLU-2         [-1, 64, 150, 150]               0\n",
      "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
      "              ReLU-4         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-5           [-1, 64, 75, 75]               0\n",
      "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
      "              ReLU-7          [-1, 128, 75, 75]               0\n",
      "            Conv2d-8          [-1, 128, 75, 75]         147,584\n",
      "              ReLU-9          [-1, 128, 75, 75]               0\n",
      "        MaxPool2d-10          [-1, 128, 37, 37]               0\n",
      "           Conv2d-11          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-12          [-1, 256, 37, 37]               0\n",
      "           Conv2d-13          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-14          [-1, 256, 37, 37]               0\n",
      "           Conv2d-15          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-16          [-1, 256, 37, 37]               0\n",
      "           Conv2d-17          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-18          [-1, 256, 37, 37]               0\n",
      "        MaxPool2d-19          [-1, 256, 18, 18]               0\n",
      "           Conv2d-20          [-1, 512, 18, 18]       1,180,160\n",
      "             ReLU-21          [-1, 512, 18, 18]               0\n",
      "           Conv2d-22          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-23          [-1, 512, 18, 18]               0\n",
      "           Conv2d-24          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-25          [-1, 512, 18, 18]               0\n",
      "           Conv2d-26          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-27          [-1, 512, 18, 18]               0\n",
      "        MaxPool2d-28            [-1, 512, 9, 9]               0\n",
      "           Conv2d-29            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-30            [-1, 512, 9, 9]               0\n",
      "           Conv2d-31            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-32            [-1, 512, 9, 9]               0\n",
      "           Conv2d-33            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-34            [-1, 512, 9, 9]               0\n",
      "           Conv2d-35            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-36            [-1, 512, 9, 9]               0\n",
      "        MaxPool2d-37            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0\n",
      "           Linear-39                 [-1, 4096]     102,764,544\n",
      "             ReLU-40                 [-1, 4096]               0\n",
      "          Dropout-41                 [-1, 4096]               0\n",
      "           Linear-42                 [-1, 4096]      16,781,312\n",
      "             ReLU-43                 [-1, 4096]               0\n",
      "          Dropout-44                 [-1, 4096]               0\n",
      "           Linear-45                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 0\n",
      "Non-trainable params: 143,667,240\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 105.45\n",
      "Params size (MB): 548.05\n",
      "Estimated Total Size (MB): 653.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Freeze the parameters to avoid backpropagation through them\n",
    "for param in vgg19.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create a new sequential model\n",
    "classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128*7*7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "# Replace the last layer of the pre-trained model with our classifier\n",
    "vgg19.fc = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbda7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dd6c027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
      "              ReLU-2         [-1, 64, 150, 150]               0\n",
      "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
      "              ReLU-4         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-5           [-1, 64, 75, 75]               0\n",
      "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
      "              ReLU-7          [-1, 128, 75, 75]               0\n",
      "            Conv2d-8          [-1, 128, 75, 75]         147,584\n",
      "              ReLU-9          [-1, 128, 75, 75]               0\n",
      "        MaxPool2d-10          [-1, 128, 37, 37]               0\n",
      "           Conv2d-11          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-12          [-1, 256, 37, 37]               0\n",
      "           Conv2d-13          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-14          [-1, 256, 37, 37]               0\n",
      "           Conv2d-15          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-16          [-1, 256, 37, 37]               0\n",
      "           Conv2d-17          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-18          [-1, 256, 37, 37]               0\n",
      "        MaxPool2d-19          [-1, 256, 18, 18]               0\n",
      "           Conv2d-20          [-1, 512, 18, 18]       1,180,160\n",
      "             ReLU-21          [-1, 512, 18, 18]               0\n",
      "           Conv2d-22          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-23          [-1, 512, 18, 18]               0\n",
      "           Conv2d-24          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-25          [-1, 512, 18, 18]               0\n",
      "           Conv2d-26          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-27          [-1, 512, 18, 18]               0\n",
      "        MaxPool2d-28            [-1, 512, 9, 9]               0\n",
      "           Conv2d-29            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-30            [-1, 512, 9, 9]               0\n",
      "           Conv2d-31            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-32            [-1, 512, 9, 9]               0\n",
      "           Conv2d-33            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-34            [-1, 512, 9, 9]               0\n",
      "           Conv2d-35            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-36            [-1, 512, 9, 9]               0\n",
      "        MaxPool2d-37            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0\n",
      "           Linear-39                 [-1, 4096]     102,764,544\n",
      "             ReLU-40                 [-1, 4096]               0\n",
      "          Dropout-41                 [-1, 4096]               0\n",
      "           Linear-42                 [-1, 4096]      16,781,312\n",
      "             ReLU-43                 [-1, 4096]               0\n",
      "          Dropout-44                 [-1, 4096]               0\n",
      "           Linear-45                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 0\n",
      "Non-trainable params: 143,667,240\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 105.45\n",
      "Params size (MB): 548.05\n",
      "Estimated Total Size (MB): 653.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vgg19,(3,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8b68c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet50 model\n",
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c92449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the parameters to avoid backpropagation through them\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create a new sequential model\n",
    "classifier = nn.Sequential(\n",
    "                      nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128*7*7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "# Replace the last layer of the pre-trained model with our classifier\n",
    "resnet50.fc = classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "572f2c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 0 %\n"
     ]
    }
   ],
   "source": [
    "val_pretrainvgg19 = val_CNN(vgg19,val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b649983c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 50 %\n"
     ]
    }
   ],
   "source": [
    "val_pretrainresnet50 = val_CNN(resnet50,val_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
